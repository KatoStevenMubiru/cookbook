{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-03T12:16:04.084282Z","iopub.execute_input":"2024-07-03T12:16:04.084682Z","iopub.status.idle":"2024-07-03T12:16:05.400159Z","shell.execute_reply.started":"2024-07-03T12:16:04.084648Z","shell.execute_reply":"2024-07-03T12:16:05.398902Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"**Description:**\n\nThis notebook aims to build a generic interaction checker that leverages Mistral AI and LlamaIndex to analyze potential interactions between drugs and genomic data. The notebook provides a step-by-step guide to set up the environment, process input data, and query the models to get interaction insights, making it a valuable tool for healthcare applications.\n\nThis notebook is developed by **Kato Steven Mubiru**","metadata":{}},{"cell_type":"markdown","source":"**Steps to Follow**\nSetup and Installation: Install the required libraries using the pip commands provided.\nAPI Key Configuration: Replace <YOUR_MISTRALAI_API_KEY> with your actual Mistral AI API key.\nLoad Data: Since this is a generic implementation, it uses placeholder data for demonstration. Users can replace this with their own data.\nRun the Example: Run the example code in a Jupyter notebook or a Python script to see the output.\nEnhancements\n\n**This implementation includes:**\n\nError handling for insufficient drug inputs.\nPlaceholder data for drug interactions.\nIntegration of LlamaIndex and Mistral AI.\nFunctions for querying both LlamaIndex and Mistral AI.\nCombined results from both sources.\nThis generic implementation can be easily adapted to real data and further enhanced with more sophisticated data handling and additional use cases. It provides a solid foundation for contributing to the Mistral AI Cookbook.","metadata":{}},{"cell_type":"code","source":"# Install the required libraries\n!pip install mistralai llama-index pandas\n\n# Import necessary libraries\nimport os\nimport pandas as pd\nimport mistralai\nfrom llama_index import SimpleDirectoryReader, GPTVectorStoreIndex, MistralAI, MistralAIEmbedding\n\n# Set up Mistral AI API key\nos.environ['MISTRAL_API_KEY'] = '<YOUR_MISTRALAI_API_KEY>'\n\n# Setup LLM and Embedding Model\nllm = MistralAI(model='mistral-large')\nembed_model = MistralAIEmbedding()\n\n# Configure LlamaIndex settings\nfrom llama_index import Settings\nSettings.llm = llm\nSettings.embed_model = embed_model\n\n# Placeholder: User-provided drug interaction data (for demonstration purposes)\n# Users will provide their own data\ndrug_interactions_data = pd.DataFrame({\n    'Drug1': ['Aspirin', 'Ibuprofen', 'Aspirin'],\n    'Drug2': ['Warfarin', 'Warfarin', 'Ibuprofen'],\n    'Interaction': [\n        'Increased risk of bleeding.',\n        'Increased risk of bleeding.',\n        'Increased risk of gastrointestinal bleeding.'\n    ]\n})\n\n# Load data into LlamaIndex\ndocuments = SimpleDirectoryReader(input_files=[\"drug_interactions.csv\"]).load_data()\nindex = GPTVectorStoreIndex.from_documents(documents)\n\n# Define functions for drug and genomics interaction checking\ndef check_drug_interactions(drugs: List[str]) -> str:\n    if len(drugs) < 2:\n        return \"Please provide at least two drugs to check for interactions.\"\n\n    # Query LlamaIndex for drug interactions\n    query = \" and \".join(drugs)\n    llama_results = index.query(query)\n\n    # Use Mistral AI API for drug interaction checking\n    prompt = f\"Check for interactions between the following drugs: {', '.join(drugs)}.\"\n    mistral_results = client.chat([{\"role\": \"user\", \"content\": prompt}])[\"choices\"][0][\"message\"][\"content\"]\n\n    # Handle errors and edge cases\n    if not llama_results:\n        llama_results = \"No interactions found in LlamaIndex.\"\n\n    # Format and return the results\n    return f\"LlamaIndex Results:\\n{llama_results}\\n\\nMistral AI Results:\\n{mistral_results}\"\n\ndef query_llama_index(drugs: List[str], genes: List[str], variants: List[str]) -> str:\n    # Combine queries for drugs, genes, and variants\n    drug_query = \" and \".join(drugs)\n    gene_query = \" and \".join(genes)\n    variant_query = \" and \".join(variants)\n    combined_query = f\"{drug_query} {gene_query} {variant_query}\"\n    \n    # Query LlamaIndex\n    llama_results = index.query(combined_query)\n    return llama_results\n\ndef query_mistral_ai_api(drugs: List[str], genes: List[str], variants: List[str]) -> str:\n    # Create prompt for Mistral AI\n    drug_prompt = f\"Check for interactions between the following drugs: {', '.join(drugs)}.\"\n    gene_prompt = f\"Check for interactions between the following genes: {', '.join(genes)}.\"\n    variant_prompt = f\"Check for information on the following genomic variants: {', '.join(variants)}.\"\n    \n    # Get responses from Mistral AI\n    drug_response = client.chat([{\"role\": \"user\", \"content\": drug_prompt}])[\"choices\"][0][\"message\"][\"content\"]\n    gene_response = client.chat([{\"role\": \"user\", \"content\": gene_prompt}])[\"choices\"][0][\"message\"][\"content\"]\n    variant_response = client.chat([{\"role\": \"user\", \"content\": variant_prompt}])[\"choices\"][0][\"message\"][\"content\"]\n    \n    # Combine responses\n    combined_results = f\"Drug Interactions:\\n{drug_response}\\n\\nGene Interactions:\\n{gene_response}\\n\\nGenomic Variants:\\n{variant_response}\"\n    return combined_results\n\ndef check_drug_genomic_interactions(drugs: List[str], genes: List[str], variants: List[str]) -> str:\n    # Query LlamaIndex for drug interactions, drug-gene interactions, and genomic variant information\n    llama_results = query_llama_index(drugs, genes, variants)\n\n    # Use Mistral AI API for drug interaction checking, drug-gene interactions, and pharmacogenomics recommendations\n    mistral_results = query_mistral_ai_api(drugs, genes, variants)\n\n    # Handle errors and edge cases\n    if not llama_results:\n        llama_results = \"No interactions found in LlamaIndex.\"\n    if not mistral_results:\n        mistral_results = \"No interactions found using Mistral AI.\"\n\n    # Format and return the results\n    return f\"LlamaIndex Results:\\n{llama_results}\\n\\nMistral AI Results:\\n{mistral_results}\"\n\n# Example usage\ndrugs = [\"Aspirin\", \"Warfarin\"]\ngenes = [\"CYP2C9\"]\nvariants = [\"rs1799853\"]\nresult = check_drug_genomic_interactions(drugs, genes, variants)\nprint(result)\n","metadata":{},"execution_count":null,"outputs":[]}]}